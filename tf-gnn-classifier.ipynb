{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fa8301-b7e9-4d98-9f59-d20477e9c91b",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow Graph Neural Networks:\n",
    "\n",
    "* https://github.com/tensorflow/gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276e7c9-c8e5-4514-b021-370659968185",
   "metadata": {},
   "source": [
    "## Graph classification example from \n",
    "* https://www.kaggle.com/code/fidels/introduction-to-tf-gnn\n",
    "## Updated to work with the current version of TF-GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa5ad6f-db0b-483d-83ed-8c61538ee8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c39a5e-ea7e-43a9-b847-c54e7676ee78",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8850e-d6f1-409f-a5b4-a59bc313c8d2",
   "metadata": {},
   "source": [
    "### For plotting graph model install and import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4bcf8-ca90-41cc-b15c-0a77aa786d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pygraphviz as pgv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb2b73-49ce-47c2-92af-7c26ca29921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Useful for debugging\n",
    "#tf.config.run_functions_eagerly(\n",
    "#    True\n",
    "#)\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_gnn import runner\n",
    "from tensorflow_gnn.models import gat_v2\n",
    "\n",
    "print(f'Using TensorFlow v{tf.__version__} and TensorFlow-GNN v{tfgnn.__version__}')\n",
    "print(f'GPUs available: {tf.config.list_physical_devices(\"GPU\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a398710-dbff-4dac-b7c4-35338108e430",
   "metadata": {},
   "source": [
    "## Loading chemical molecules dataset\n",
    "## DS contains splits into: train, test-iid, test-ood1, test-ood2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d5de26-61e6-47e2-aaee-c6f5ccbcd8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Cardiotoxicity dataset [1-2] is a molecule classification task to detect\n",
      "cardiotoxicity caused by binding hERG target, a protein associated with heart\n",
      "beat rhythm. The data covers over 9000 molecules with hERG activity.\n",
      "\n",
      "Note:\n",
      "\n",
      "1. The data is split into four splits: train, test-iid, test-ood1, test-ood2.\n",
      "\n",
      "2. Each molecule in the dataset has 2D graph annotations which is designed to\n",
      "facilitate graph neural network modeling. Nodes are the atoms of the molecule\n",
      "and edges are the bonds. Each atom is represented as a vector encoding basic\n",
      "atom information such as atom type. Similar logic applies to bonds.\n",
      "\n",
      "3. We include Tanimoto fingerprint distance (to training data) for each molecule\n",
      "in the test sets to facilitate research on distributional shift in graph domain.\n",
      "\n",
      "For each example, the features include:\n",
      "  atoms: a 2D tensor with shape (60, 27) storing node features. Molecules with\n",
      "    less than 60 atoms are padded with zeros. Each atom has 27 atom features.\n",
      "  pairs: a 3D tensor with shape (60, 60, 12) storing edge features. Each edge\n",
      "    has 12 edge features.\n",
      "  atom_mask: a 1D tensor with shape (60, ) storing node masks. 1 indicates the\n",
      "    corresponding atom is real, othewise a padded one.\n",
      "  pair_mask: a 2D tensor with shape (60, 60) storing edge masks. 1 indicates the\n",
      "    corresponding edge is real, othewise a padded one.\n",
      "  active: a one-hot vector indicating if the molecule is toxic or not. [0, 1]\n",
      "    indicates it's toxic, otherwise [1, 0] non-toxic.\n",
      "\n",
      "\n",
      "## References\n",
      "[1]: V. B. Siramshetty et al. Critical Assessment of Artificial Intelligence\n",
      "Methods for Prediction of hERG Channel Inhibition in the Big Data Era.\n",
      "    JCIM, 2020. https://pubs.acs.org/doi/10.1021/acs.jcim.0c00884\n",
      "\n",
      "[2]: K. Han et al. Reliable Graph Neural Networks for Drug Discovery Under\n",
      "Distributional Shift.\n",
      "    NeurIPS DistShift Workshop 2021. https://arxiv.org/abs/2111.12951\n"
     ]
    }
   ],
   "source": [
    "dataset_splits, dataset_info = tfds.load('cardiotox', data_dir='data/tfds', with_info=True)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print(dataset_info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea09ae-8a60-4691-a2e8-6352c86f6a13",
   "metadata": {},
   "source": [
    "## Detailed detaset informations including numbers of samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a20fb88-8359-475a-9382-45f75d63b6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='cardiotox',\n",
       "    full_name='cardiotox/1.0.0',\n",
       "    description=\"\"\"\n",
       "    Drug Cardiotoxicity dataset [1-2] is a molecule classification task to detect\n",
       "    cardiotoxicity caused by binding hERG target, a protein associated with heart\n",
       "    beat rhythm. The data covers over 9000 molecules with hERG activity.\n",
       "    \n",
       "    Note:\n",
       "    \n",
       "    1. The data is split into four splits: train, test-iid, test-ood1, test-ood2.\n",
       "    \n",
       "    2. Each molecule in the dataset has 2D graph annotations which is designed to\n",
       "    facilitate graph neural network modeling. Nodes are the atoms of the molecule\n",
       "    and edges are the bonds. Each atom is represented as a vector encoding basic\n",
       "    atom information such as atom type. Similar logic applies to bonds.\n",
       "    \n",
       "    3. We include Tanimoto fingerprint distance (to training data) for each molecule\n",
       "    in the test sets to facilitate research on distributional shift in graph domain.\n",
       "    \n",
       "    For each example, the features include:\n",
       "      atoms: a 2D tensor with shape (60, 27) storing node features. Molecules with\n",
       "        less than 60 atoms are padded with zeros. Each atom has 27 atom features.\n",
       "      pairs: a 3D tensor with shape (60, 60, 12) storing edge features. Each edge\n",
       "        has 12 edge features.\n",
       "      atom_mask: a 1D tensor with shape (60, ) storing node masks. 1 indicates the\n",
       "        corresponding atom is real, othewise a padded one.\n",
       "      pair_mask: a 2D tensor with shape (60, 60) storing edge masks. 1 indicates the\n",
       "        corresponding edge is real, othewise a padded one.\n",
       "      active: a one-hot vector indicating if the molecule is toxic or not. [0, 1]\n",
       "        indicates it's toxic, otherwise [1, 0] non-toxic.\n",
       "    \n",
       "    \n",
       "    ## References\n",
       "    [1]: V. B. Siramshetty et al. Critical Assessment of Artificial Intelligence\n",
       "    Methods for Prediction of hERG Channel Inhibition in the Big Data Era.\n",
       "        JCIM, 2020. https://pubs.acs.org/doi/10.1021/acs.jcim.0c00884\n",
       "    \n",
       "    [2]: K. Han et al. Reliable Graph Neural Networks for Drug Discovery Under\n",
       "    Distributional Shift.\n",
       "        NeurIPS DistShift Workshop 2021. https://arxiv.org/abs/2111.12951\n",
       "    \"\"\",\n",
       "    homepage='https://github.com/google/uncertainty-baselines/tree/main/baselines/drug_cardiotoxicity',\n",
       "    data_dir='data/tfds/cardiotox/1.0.0',\n",
       "    file_format=tfrecord,\n",
       "    download_size=Unknown size,\n",
       "    dataset_size=1.66 GiB,\n",
       "    features=FeaturesDict({\n",
       "        'active': Tensor(shape=(2,), dtype=int64),\n",
       "        'atom_mask': Tensor(shape=(60,), dtype=float32),\n",
       "        'atoms': Tensor(shape=(60, 27), dtype=float32),\n",
       "        'dist2topk_nbs': Tensor(shape=(1,), dtype=float32),\n",
       "        'molecule_id': string,\n",
       "        'pair_mask': Tensor(shape=(60, 60), dtype=float32),\n",
       "        'pairs': Tensor(shape=(60, 60, 12), dtype=float32),\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=839, num_shards=2>,\n",
       "        'test2': <SplitInfo num_examples=177, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=6523, num_shards=16>,\n",
       "        'validation': <SplitInfo num_examples=1631, num_shards=4>,\n",
       "    },\n",
       "    citation=\"\"\"@ARTICLE{Han2021-tu,\n",
       "      title         = \"Reliable Graph Neural Networks for Drug Discovery Under\n",
       "                       Distributional Shift\",\n",
       "      author        = \"Han, Kehang and Lakshminarayanan, Balaji and Liu, Jeremiah\",\n",
       "      month         =  nov,\n",
       "      year          =  2021,\n",
       "      archivePrefix = \"arXiv\",\n",
       "      primaryClass  = \"cs.LG\",\n",
       "      eprint        = \"2111.12951\"\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5ea69-99d8-4d40-b285-6069522b4d55",
   "metadata": {},
   "source": [
    "## A brief look into the raw training dataset tensors forming one molecule sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a163bec-e22c-46c4-8548-faea64ca21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset_splits['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0cb5d2-c4ec-4252-b1cf-65c2634061af",
   "metadata": {},
   "source": [
    "## Sample is a dictionary of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d79c2b3-d366-433e-8c4e-99b7c4428398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['active', 'atom_mask', 'atoms', 'dist2topk_nbs', 'molecule_id', 'pair_mask', 'pairs'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5951467d-1060-4215-bfc3-071e672c2193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 0])>,\n",
       " 'atom_mask': <tf.Tensor: shape=(60,), dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " 'atoms': <tf.Tensor: shape=(60, 27), dtype=float32, numpy=\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " 'dist2topk_nbs': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'molecule_id': <tf.Tensor: shape=(), dtype=string, numpy=b'CC1=C(C/C=C(\\\\C)CCC[C@H](C)CCC[C@H](C)CCCC(C)C)C(=O)c2ccccc2C1=O'>,\n",
       " 'pair_mask': <tf.Tensor: shape=(60, 60), dtype=float32, numpy=\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " 'pairs': <tf.Tensor: shape=(60, 60, 12), dtype=float32, numpy=\n",
       " array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 1., 1., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[1., 0., 0., ..., 1., 1., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afafe506-5d5f-456d-a7ec-2b9586de2c59",
   "metadata": {},
   "source": [
    "## TF-GNN works with graphs by employing a particular data representations defined by a *Graph Schema*\n",
    "## Schema is used to prepare a GraphTensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79bc85d-f0c1-4bbb-a5ba-e369933d7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_schema_pbtxt = \"\"\"\n",
    "node_sets {\n",
    "  key: \"atom\"\n",
    "  value {\n",
    "    description: \"An atom in the molecule.\"\n",
    "\n",
    "    features {\n",
    "      key: \"atom_features\"\n",
    "      value: {\n",
    "        description: \"[DATA] The features of the atom.\"\n",
    "        dtype: DT_FLOAT\n",
    "        shape { dim { size: 27 } }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "edge_sets {\n",
    "  key: \"bond\"\n",
    "  value {\n",
    "    description: \"A bond between two atoms in the molecule.\"\n",
    "    source: \"atom\"\n",
    "    target: \"atom\"\n",
    "\n",
    "    features {\n",
    "      key: \"bond_features\"\n",
    "      value: {\n",
    "        description: \"[DATA] The features of the bond.\"\n",
    "        dtype: DT_FLOAT\n",
    "        shape { dim { size: 12 } }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "context {\n",
    "  features {\n",
    "    key: \"toxicity\"\n",
    "    value: {\n",
    "      description: \"[LABEL] The toxicity class of the molecule (0 -> non-toxic; 1 -> toxic).\"\n",
    "      dtype: DT_INT64\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  features {\n",
    "    key: \"molecule_id\"\n",
    "    value: {\n",
    "      description: \"[LABEL] The id of the molecule.\"\n",
    "      dtype: DT_STRING\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abb9b09-6310-4fa4-a6c0-5a8cdac36cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_schema = tfgnn.parse_schema(graph_schema_pbtxt)\n",
    "graph_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9085a55c-4848-44a9-8f78-0d593ad7aa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {'toxicity': TensorSpec(shape=(1,), dtype=tf.int64, name=None), 'molecule_id': TensorSpec(shape=(1,), dtype=tf.string, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None), 'node_sets': {'atom': NodeSetSpec({'features': {'atom_features': TensorSpec(shape=(None, 27), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None)}, 'edge_sets': {'bond': EdgeSetSpec({'features': {'bond_features': TensorSpec(shape=(None, 12), dtype=tf.float32, name=None)}, 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, {'#index.0': 'atom', '#index.1': 'atom'}), 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None)}}, TensorShape([]), tf.int32, tf.int64, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ab665-6a55-464c-9cc2-1f5dcfa118a2",
   "metadata": {},
   "source": [
    "## A function is defined to import data from the the raw dataset tensors into structures defined by the schema\n",
    "## The raw dataset contains paddings for both atoms (nodes) and bonds (edges), which are removed with corresponding masks provided in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c4cb1a-159c-47e4-ba63-3e3deb4c73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_tensor(datapoint):\n",
    "    \"\"\"\n",
    "    Convert a datapoint from the TF-DS CardioTox dataset into a `GraphTensor`.\n",
    "    \"\"\"\n",
    "    # atom_mask is non-zero only for real atoms\n",
    "    # [ V, ]\n",
    "    atom_indices = tf.squeeze(tf.where(datapoint['atom_mask']), axis=1)\n",
    "    \n",
    "    # only keep features of real atoms\n",
    "    # [ V, 27 ]\n",
    "    atom_features = tf.gather(datapoint['atoms'], atom_indices)\n",
    "    \n",
    "    # restrict the bond mask to real atoms\n",
    "    # [ V, V ]\n",
    "    pair_mask = tf.gather(tf.gather(datapoint['pair_mask'], atom_indices, axis=0), atom_indices, axis=1)\n",
    "    \n",
    "    # restrict the bond features to real atoms\n",
    "    # [ V, V, 12 ]\n",
    "    pairs = tf.gather(tf.gather(datapoint['pairs'], atom_indices, axis=0), atom_indices, axis=1)\n",
    "    \n",
    "    # pair_mask is non-zero only for real bonds\n",
    "    # [ E, 2 ]\n",
    "    bond_indices = tf.where(pair_mask)\n",
    "    \n",
    "    # only keep features of real bonds\n",
    "    # [ E, 12 ]\n",
    "    bond_features = tf.gather_nd(pairs, bond_indices)\n",
    "    \n",
    "    # separate sources and targets for each bond\n",
    "    # [ E, ]\n",
    "    sources, targets = tf.unstack(tf.transpose(bond_indices))\n",
    "\n",
    "    # active is [1, 0] for non-toxic molecules, [0, 1] for toxic molecules\n",
    "    # [ ]\n",
    "    toxicity = tf.argmax(datapoint['active'])\n",
    "    \n",
    "    # the molecule_id is included for reference\n",
    "    # [ ]\n",
    "    molecule_id = datapoint['molecule_id']\n",
    "\n",
    "    # create a GraphTensor from all of the above\n",
    "    atom = tfgnn.NodeSet.from_fields(features={'atom_features': atom_features},\n",
    "                                     sizes=tf.shape(atom_indices))\n",
    "    \n",
    "    atom_adjacency = tfgnn.Adjacency.from_indices(source=('atom', tf.cast(sources, dtype=tf.int32)),\n",
    "                                                  target=('atom', tf.cast(targets, dtype=tf.int32)))\n",
    "    \n",
    "    bond = tfgnn.EdgeSet.from_fields(features={'bond_features': bond_features},\n",
    "                                     sizes=tf.shape(sources),\n",
    "                                     adjacency=atom_adjacency)\n",
    "    \n",
    "    context = tfgnn.Context.from_fields(features={'toxicity': [toxicity], 'molecule_id': [molecule_id]})\n",
    "    \n",
    "    return tfgnn.GraphTensor.from_pieces(node_sets={'atom': atom}, edge_sets={'bond': bond}, context=context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2dd49-f18a-4c24-aa40-dadb0af3658d",
   "metadata": {},
   "source": [
    "## Mapping the dataset into the ragged form without padded graph elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76a0e29c-857a-46d9-bdca-9c5f1f81147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_splits['train'].map(make_graph_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c786b50-0884-4038-8b87-9a882850d091",
   "metadata": {},
   "source": [
    "## Taking one sample, same as the one in the raw dataset above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef8082e4-5e39-41b2-83df-c7adcab3a5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={'toxicity': <tf.Tensor: shape=(1,), dtype=tf.int64>, 'molecule_id': <tf.Tensor: shape=(1,), dtype=tf.string>}, sizes=[1], shape=(), indices_dtype=tf.int32),\n",
       "  node_set_names=['atom'],\n",
       "  edge_set_names=['bond'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor = next(iter(train_dataset))\n",
    "graph_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ab303-bdc3-4779-96bd-90c4f7d7fb4e",
   "metadata": {},
   "source": [
    "## Verification, that the resulting dataset is compliant with the graph schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15438ceb-6997-45b5-a7ee-a9522f1d3dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_spec.is_compatible_with(graph_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f5ecf-45dd-4ce9-adfa-d5812ddc39bb",
   "metadata": {},
   "source": [
    "## Looking into the transformed tensors\n",
    "\n",
    "## Edge and atom sets below have sizes varying based on the actual atoms and bond counts in molecules (feature dimensions are the same 12 and 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38b0794-4afb-47cd-8651-081094e518ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {'toxicity': TensorSpec(shape=(1,), dtype=tf.int64, name=None), 'molecule_id': TensorSpec(shape=(1,), dtype=tf.string, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None), 'node_sets': {'atom': NodeSetSpec({'features': {'atom_features': TensorSpec(shape=(33, 27), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None)}, 'edge_sets': {'bond': EdgeSetSpec({'features': {'bond_features': TensorSpec(shape=(68, 12), dtype=tf.float32, name=None)}, 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(68,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(68,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, {'#index.0': 'atom', '#index.1': 'atom'}), 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None)}}, TensorShape([]), tf.int32, tf.int64, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a390af-8a91-4943-a603-49d318696b14",
   "metadata": {},
   "source": [
    "## Edges are represented as two source, target lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a766b2-7da9-46c9-a697-77c0655abe39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bond': EdgeSet(features={'bond_features': <tf.Tensor: shape=(68, 12), dtype=tf.float32>}, sizes=[68], adjacency=Adjacency(source=('atom', <tf.Tensor: shape=(68,), dtype=tf.int32>), target=('atom', <tf.Tensor: shape=(68,), dtype=tf.int32>)))}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3359cc5a-4123-4227-852c-6a42065c7aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([68], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of edges E in this molecule graph\n",
    "graph_tensor.edge_sets['bond'].sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8056b73-ac47-4026-9040-5aa6c7a2cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(68,), dtype=int32, numpy=\n",
       "array([ 0,  1,  1,  1,  2,  2,  2,  3,  3,  4,  4,  5,  5,  5,  6,  7,  7,\n",
       "        8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 14, 14, 15, 15, 15,\n",
       "       16, 17, 17, 18, 18, 19, 19, 20, 20, 20, 21, 22, 23, 23, 23, 24, 25,\n",
       "       25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 30, 31, 31, 31, 32],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets['bond'].adjacency.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73d3f871-102d-4c9b-9038-1a611a81ad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(68,), dtype=int32, numpy=\n",
       "array([ 1,  0,  2, 31,  1,  3, 23,  2,  4,  3,  5,  4,  6,  7,  5,  5,  8,\n",
       "        7,  9,  8, 10,  9, 11, 12, 10, 10, 13, 12, 14, 13, 15, 14, 16, 17,\n",
       "       15, 15, 18, 17, 19, 18, 20, 19, 21, 22, 20, 20,  2, 24, 25, 23, 23,\n",
       "       26, 30, 25, 27, 26, 28, 27, 29, 28, 30, 25, 29, 31,  1, 30, 32, 31],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets['bond'].adjacency.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4ae8e-6699-4805-9710-c6751d8e9bfe",
   "metadata": {},
   "source": [
    "## Each edge in this unoriented graph is endowed with 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19140c55-89cc-44cf-bf87-2b86ff611fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(68, 12), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets['bond']['bond_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da8322-f225-4909-ba78-9e1042f63ed4",
   "metadata": {},
   "source": [
    "## Nodes (atoms) are simply listed as their feature vectors of dim==27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20c756a7-f47d-4308-80b9-4e31f7d6d8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeSet(features={'atom_features': <tf.Tensor: shape=(33, 27), dtype=tf.float32>}, sizes=[33])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.node_sets['atom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97a3ee47-e658-44de-8ee4-fa344fea3248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([33], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nodes V in his molecules\n",
    "graph_tensor.node_sets['atom'].sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "761c5275-97cf-49ec-b62f-ab51b95252e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(33, 27), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 2., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 2., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.node_sets['atom']['atom_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82f73a-af02-40a7-bd04-6895c87fc176",
   "metadata": {},
   "source": [
    "## The target for the GNN binary classifier is stored in the molecule context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109f42e0-0668-459e-b4e5-3e21ae66988c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.context.features['toxicity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99633524-2140-4316-890f-653ad4449f51",
   "metadata": {},
   "source": [
    "## For performance we store the dataset in TFRecords, which may allow for distributed GPU and TPU training\n",
    "\n",
    "## From the original article:\n",
    "### \"tf.data.Dataset.cache or tf.data.Dataset.snapshot would be preferable, as they would allow for more optimizations such as e.g. sharding.\"\n",
    "\n",
    "## These methods allow for file or memory persistence of preprocessed data to save on dataset preparation\n",
    "\n",
    "## The code below just dumps data to TFR without multiple files optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31c598bb-5e8e-43ec-b295-7ce925c8aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecords(dataset_splits, dataset_info):\n",
    "    \"\"\"\n",
    "    Dump all splits of the given dataset to TFRecord files.\n",
    "    \"\"\"\n",
    "    for split_name, dataset in dataset_splits.items():\n",
    "        filename = f'data/{dataset_info.name}-{split_name}.tfrecord'\n",
    "        \n",
    "        print(f'Creating {filename}')\n",
    "\n",
    "        # Mapping the raw dataser to GraphTensors with parallel processing\n",
    "        dataset = dataset.map(make_graph_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        # Serializing to TFRs\n",
    "        with tf.io.TFRecordWriter(filename) as writer:\n",
    "            # We explicitly limit iteration over the dataset to one pass\n",
    "            for graph_tensor in tqdm(iter(dataset), total=dataset_info.splits[split_name].num_examples):\n",
    "                example = tfgnn.write_example(graph_tensor)\n",
    "                writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4a25e-aceb-4482-9d30-363cc6c9b6c0",
   "metadata": {},
   "source": [
    "## Creating TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "551582c9-3bbd-4b1b-a4d3-639a0a3093b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_tfrecords(dataset_splits, dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a97702-632a-4fe7-81db-69ec2669656a",
   "metadata": {},
   "source": [
    "## Dataset retrieval method: TFRecordDataserProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f2773e6-237c-44f1-9f06-0757fb382bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-train.tfrecord')\n",
    "valid_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-validation.tfrecord')\n",
    "test1_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-test.tfrecord')\n",
    "test2_dataset_provider = runner.TFRecordDatasetProvider(file_pattern='data/cardiotox-test2.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f19ea29-38ec-4eeb-85ad-fa20f4a76655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_gnn.runner.input.datasets.TFRecordDatasetProvider at 0x7ff1277528b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9465d64b-e843-43a0-9cdd-62f38efe6b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SimpleDatasetProvider.get_dataset of <tensorflow_gnn.runner.input.datasets.TFRecordDatasetProvider object at 0x7ff1277528b0>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_provider.get_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f1ba0-16c4-4538-a11e-05e57909abc3",
   "metadata": {},
   "source": [
    "## Retrieving the dataset\n",
    "\n",
    "## tf.distribute.InputContext() automatically determines batching and sharding for distributed training with many replicas in sync (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dddcd4b2-fc44-4da1-b1ad-4078140a2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_provider.get_dataset(context=tf.distribute.InputContext())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ed22c-b7fc-4e9d-a6df-3eef1e09aba4",
   "metadata": {},
   "source": [
    "## Unpacking TFRecord dataset from the serialized form requires mapping with a providied tensor spec for the data to deserialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa3e29d7-f86d-43e3-87e8-c231e869a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda serialized: tfgnn.parse_single_example(serialized=serialized, spec=graph_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b16c5-f685-4fd8-b7bf-eef243b45f51",
   "metadata": {},
   "source": [
    "## Computing class balance and baseline random classifier accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e44e249-7783-4c60-a076-0ed7f45670bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = []\n",
    "#for sample in train_dataset:\n",
    "#    labels.append(sample.context['toxicity'].numpy()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ed5b807-0c6c-4f82-ba70-571278f1393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee6134f4-104e-4853-8baf-f81680e9640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-np.sum(labels)/len(labels)\n",
    "# BASELINE --> 0.7361643415606316"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b216187-bd56-47dc-aed9-7ea1fc704802",
   "metadata": {},
   "source": [
    "## RANDOM BASELINE --> 0.7361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e35be7d-6cd4-427d-a558-b2f742a10dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_tensor = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af9f2c-ede9-4340-9329-5d9c394bd08c",
   "metadata": {},
   "source": [
    "## Graph sample can be inspected again as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "887329c1-2ee4-4903-bbeb-44d093ec78c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={'toxicity': <tf.Tensor: shape=(1,), dtype=tf.int64>, 'molecule_id': <tf.Tensor: shape=(1,), dtype=tf.string>}, sizes=[1], shape=(), indices_dtype=tf.int32),\n",
       "  node_set_names=['atom'],\n",
       "  edge_set_names=['bond'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7c00d-b85f-4ed1-91f6-4f04bdfb25c0",
   "metadata": {},
   "source": [
    "## Visualizing the sample graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faa9a647-4a65-4ae9-b94a-229b3677029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_molecule(graph_tensor):\n",
    "    \"\"\"\n",
    "    Plot the `Graph Tensor` representation of a molecule\n",
    "    \"\"\"\n",
    "    (molecule_id, ) = graph_tensor.context['molecule_id'].numpy()\n",
    "    (toxicity, ) = graph_tensor.context['toxicity'].numpy()\n",
    "\n",
    "    sources = graph_tensor.edge_sets['bond'].adjacency.source.numpy()\n",
    "    targets = graph_tensor.edge_sets['bond'].adjacency.target.numpy()\n",
    "\n",
    "    pgvGraph = pgv.AGraph()\n",
    "    pgvGraph.graph_attr['label'] = f'toxicity = {toxicity}\\n\\nmolecule_id = {molecule_id.decode()}'\n",
    "\n",
    "    for edge in zip(sources, targets):\n",
    "        pgvGraph.add_edge(edge)\n",
    "\n",
    "    return Image(pgvGraph.draw(format='png', prog='dot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fdeac5-df9e-4a6c-9163-5e17350b453d",
   "metadata": {},
   "source": [
    "## Printing the sample graphs - use with GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "002f8648-fc57-4751-9fe4-e34b58539917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_molecule(graph_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0b94d-6839-4e4c-bf86-6a6477c5bffd",
   "metadata": {},
   "source": [
    "## Batching the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6650059-eaa0-40d4-9fc8-2902efedc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "batched_train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "494a857d-a8ba-4a95-ac81-50df0204ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_tensor_item = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a2c3194-4d83-4537-92f3-c7eeff33c38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={'toxicity': <tf.Tensor: shape=(1,), dtype=tf.int64>, 'molecule_id': <tf.Tensor: shape=(1,), dtype=tf.string>}, sizes=[1], shape=(), indices_dtype=tf.int32),\n",
       "  node_set_names=['atom'],\n",
       "  edge_set_names=['bond'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "929ecbff-15f6-4e9a-a8d6-839b514ba7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_item.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b00b7d3-9430-4164-be8d-e226231308ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_tensor_batch = next(iter(batched_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93e68d88-fcee-4018-b87c-6bf301a811b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={'toxicity': <tf.Tensor: shape=(128, 1), dtype=tf.int64>, 'molecule_id': <tf.Tensor: shape=(128, 1), dtype=tf.string>}, sizes=[[1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]\n",
       " [1]], shape=(128,), indices_dtype=tf.int32),\n",
       "  node_set_names=['atom'],\n",
       "  edge_set_names=['bond'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32038e79-38d0-4b1c-ae43-d46599077a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_batch.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af7ec989-d89c-4e23-bc84-8e00215db238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([33, 27])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_item.node_sets['atom']['atom_features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a0d7d-74f8-412c-84a1-e428ba407a89",
   "metadata": {},
   "source": [
    "## After batching individual samples are stored as ragged tensors because each graph in the batch may contain a different number of nodes or edges: hence the node dimension is set to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31f75d8b-e832-41da-9205-d0ba54913256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, None, 27])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rsulting shape: (batch_size, None, atom_fetures_dimension)\n",
    "graph_tensor_batch.node_sets['atom']['atom_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80baa2b3-000a-477a-9f0a-c8c0e77a28c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, None, 12])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor_batch.edge_sets['bond']['bond_features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27cd22d-0300-4963-b484-bc47368b5b8a",
   "metadata": {},
   "source": [
    "## GNN layers expect flat scalar graph data without division into separate tensors\n",
    "\n",
    "## One needs to merge all the graphs in the batch into one graph data with batch_size disconnected components\n",
    "\n",
    "## TF-GNN keeps track of these disconnected graphs automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "427d96c2-867e-4f6d-b557-88d931d22bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor = graph_tensor_batch.merge_batch_to_components()\n",
    "scalar_graph_tensor.rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc5ed6-7d9f-4ec7-9ce4-cc761b86d0be",
   "metadata": {},
   "source": [
    "## Now the number of nodes and edges in explicitly accessible again, with counts reflecting the sum of all vertices and edges in the batch graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49f68bbf-1550-4b10-94be-1f2153c84fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3368, 27])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor.node_sets['atom']['atom_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "babeaea3-ee21-4ba4-b619-d65426930344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7312, 12])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor.edge_sets['bond']['bond_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2e7aa17-e797-4dbd-82cd-89bcdf0b8df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
       "array([0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor.context.features['toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "785c6a5f-a0c9-43d8-902a-41dcba537a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxicity': <tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
       "array([0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])>, 'molecule_id': <tf.Tensor: shape=(128,), dtype=string, numpy=\n",
       "array([b'CC1=C(C/C=C(\\\\C)CCC[C@H](C)CCC[C@H](C)CCCC(C)C)C(=O)c2ccccc2C1=O',\n",
       "       b'CC(=O)N1CCN(c2cnc3cc(C(F)(F)F)cc(NCc4cccc([N+](=O)[O-])c4)c3c2)CC1',\n",
       "       b'COc1c(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)N(C)C)n2)ccc2c1CCCC(N1CCN(CCO)CC1)C2',\n",
       "       b'CCCCCCCC/C=C\\\\CCCCCCCC(=O)O',\n",
       "       b'CCN(CC)C(=O)c1ccc([C@H](c2cccc(NC(=O)OC)c2)N2CCN(Cc3cccnc3)CC2)cc1',\n",
       "       b'FC(F)(F)c1cc(CO[C@H]2CCCN[C@H]2c2ccccc2)cc(C(F)(F)F)c1',\n",
       "       b'Cc1ccc(Br)cc1', b'CNC1CN(c2nc(N)nc3cc(C4CCCC4)ccc23)C1',\n",
       "       b'C=N[C@@H](C(=O)N[C@@H]1C(=O)N2[C@@H](C(=O)O)C(C)(C)S[C@H]12)c1ccccc1',\n",
       "       b'CCCCCCCCCCCC(=O)O',\n",
       "       b'COc1ccc(OC)c(Cc2nc3ccccc3n2CC(=O)Nc2cc(C(C)(C)C)cc(C(C)(C)C)c2)c1',\n",
       "       b'Cc1ccc(OC(=O)N(CC(=O)O)Cc2cccc(OCc3nc(-c4ccc(C)cc4)oc3C)c2)cc1',\n",
       "       b'CC[C@@]1(c2cccc(NS(C)(=O)=O)c2)[C@H]2CN(CCCC3(O)CCCCC3)C[C@H]21',\n",
       "       b'C[C@]12C(=O)OC(=O)[C@@]1(C)C1CCC2O1',\n",
       "       b'CC1(C)[C@H](Nc2c(C(N)=O)cnn3cc(-c4ccccc4)cc23)CC[C@]1(C)N',\n",
       "       b'CCCCCCCN(CC)CC#CCOCc1ccc(Cl)cc1',\n",
       "       b'O=C(N[C@H]1CCCC[C@@H]1O)c1cc(CN2CCN(c3cc4scnc4cn3)CC2)c2ccccn2c1=O',\n",
       "       b'O=C(O)COc1ccc(Cl)cc1Cl', b'c1cc2c(c(N3CCNCC3)c1)OCCO2',\n",
       "       b'CONC(=O)N(Cc1ccsc1)C1CCN([C@H](C)CCNC(=O)c2c(C)cc(Cl)nc2Cl)CC1',\n",
       "       b'Cc1ccncc1-c1cc2c(N[C@@H]3CC[C@](C)(N)C3(C)C)c(C(N)=O)cnn2c1',\n",
       "       b'Cc1ncoc1-c1nnc(SCCCN2CC[C@]3(C[C@H]3c3ccc(C(F)(F)F)cc3F)C2)n1C',\n",
       "       b'Cc1cn([C@H]2C[C@H](O)[C@@H](CO)O2)c(=O)[nH]c1=O',\n",
       "       b'c1ccc(CCN2CCCC(c3c(-c4ccccc4)[nH]c4ccccc34)C2)cc1',\n",
       "       b'O=C(Cc1ccc(Cl)c(Cl)c1)OCCN1CCCC1',\n",
       "       b'CC(C)OC[C@H](Oc1ncnc2c1cnn2-c1ccccc1Cl)C(=O)Nc1ccccn1',\n",
       "       b'Nc1nc2cc3c(cc2s1)CCN(C1CC1)CC3',\n",
       "       b'Cc1cc(O)c2c(O)c3c4c5c(cc(O)c1c25)C(C)(C)C(=O)C=4C(=O)C=C3O',\n",
       "       b'CNC[C@H](O)c1cccc(O)c1', b'CCCCCCCCc1cccc(CCCCCCCC)[n+]1C',\n",
       "       b'N#Cc1ccc(Cn2cncc2CN[C@H]2CCN(C(=O)c3cccnc3S)C2=O)cc1',\n",
       "       b'CCC(Cc1c(I)cc(I)c(O)c1I)C(=O)O',\n",
       "       b'CC(C)NC[C@@H](O)COc1ccc(CC(N)=O)cc1', b'CC(=O)OCc1ccco1',\n",
       "       b'CC(C)C[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)c1cnccn1)B(O)O',\n",
       "       b'CCCCNC(=O)NS(=O)(=O)c1ccc(N)cc1',\n",
       "       b'CCCCC(C)(O)C/C=C/[C@H]1[C@H](O)CC(=O)[C@@H]1CCCCCCC(=O)OC',\n",
       "       b'O=S(=O)(c1ccccc1F)C1(F)CCN(CCc2ccc(F)cc2F)CC1',\n",
       "       b'COc1ccc([C@]2(O)CC[C@H](N3CC(NC(=O)CNC(=O)c4cccc(C(F)(F)F)c4)C3)CC2)nc1',\n",
       "       b'Cc1ccc(Cl)c(O)c1',\n",
       "       b'O=C(CNc1n[nH]c2ccc(C(F)(F)F)cc12)NC1CN([C@H]2CC[C@@H](n3ccccc3=O)CC2)C1',\n",
       "       b'Cc1ccc([N+](=O)[O-])c(C)c1',\n",
       "       b'CN(C)CCc1c[nH]c2ccc(C[C@H]3COC(=O)N3)cc12',\n",
       "       b'OC(c1ccccc1)(c1ccccc1)C1CCN(CCCOc2ccc(-c3ccccc3)cc2)CC1',\n",
       "       b'S=C(S)NCCNC(=S)S.[Zn+2]', b'CCC1(c2ccccc2)C(=O)NCNC1=O',\n",
       "       b'CN([C@@H]1CCc2c(CC(=O)O)c3ccc(F)cc3n2C1)S(=O)(=O)c1ccc(F)cc1',\n",
       "       b'OCc1ccccn1',\n",
       "       b'COc1cc(N2C(=O)N(c3ccc(-c4ccc5nc[nH]c5c4)cc3)C(=O)C23CCN(Cc2ncccc2C)CC3)ncn1',\n",
       "       b'Clc1ccc(Cl)c(Cl)c1Cl', b'ClCCOCCCl',\n",
       "       b'COc1cc(S(C)=O)ccc1-c1nc2ncccc2[nH]1',\n",
       "       b'Cc1ccc2c(-c3nnc(SCCCN4CCc5cc6onc(C)c6cc5CC4)n3C)cccc2n1',\n",
       "       b'CC(C)[C@@H](CN1CCC(c2ccccc2)CC1)NC(=O)[C@H]1Cc2ccc(O)cc2CN1',\n",
       "       b'COC1=C(OC)C(=O)C(CCCCCCCCCCO)=C(C)C1=O',\n",
       "       b'C[C@@H]1O[C@@H](O[C@@H]2C=C3CC[C@@H]4[C@H](CC[C@]5(C)[C@@H](c6ccc(=O)oc6)CC[C@]45O)[C@@]3(C)CC2)[C@H](O)[C@H](O)[C@H]1O',\n",
       "       b'CN(C)C(=O)c1ccc(C(=C2CCN(Cc3cscn3)CC2)c2ccccn2)cc1',\n",
       "       b'O=C(O)[C@H]1/C(=C/CO)O[C@@H]2CC(=O)N21',\n",
       "       b'CN(CCCN1c2ccccc2CCc2ccccc21)CC(=O)c1ccc(Cl)cc1',\n",
       "       b'CC(=O)[C@H]1CC[C@H]2[C@@H]3C=CC4=CC(=O)CC[C@@]4(C)[C@@H]3CC[C@]12C',\n",
       "       b'CCc1n[nH]c(CC)c1Oc1cc(Cl)cc(C#N)c1',\n",
       "       b'COc1c(N2C[C@@H]3CCCN[C@@H]3C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC3)c12',\n",
       "       b'Cc1c(Cl)cccc1Nc1ncccc1C(=O)O',\n",
       "       b'Cc1cc(O)c2c(c1)O[C@@]1(C)CC[C@H]3C(C)(C)CCCC34CO[C@@H]2[C@H]41',\n",
       "       b'CN1[C@H]2CC[C@@H]1C[C@@H](OC(=O)C(CO)c1ccccc1)C2',\n",
       "       b'CCCCCCCCCCCCCCNCCO',\n",
       "       b'COc1cnc(-c2cccc3c2C[C@H](NC(=O)c2ccc(COCC(F)(F)F)nc2)CO3)cn1',\n",
       "       b'CCN(CC)C(=O)c1ccc(C(=C2CCNCC2)c2ccccn2)cc1',\n",
       "       b'Cc1nc2cnc(Oc3ccc(Cl)cc3F)cc2c(=O)n1C[C@H]1CCCN(C(C)C)C1',\n",
       "       b'O=C(N/N=C/c1ccc([N+](=O)[O-])o1)c1cc([N+](=O)[O-])cc([N+](=O)[O-])c1O',\n",
       "       b'CC(C)(C)c1ccc(C(=O)NCC2CCN(C(=O)CCCCC(c3ccc(F)cc3)c3ccc(F)cc3)C2)cc1',\n",
       "       b'Fc1c(Cn2ccc3c(OC4CCN(Cc5cscn5)CC4)ncnc32)cccc1C(F)(F)F',\n",
       "       b'CC1(C)Cc2cccc(CN3CCC4(CC3)CCN(C(=O)c3ccc(N)cn3)CC4)c2O1',\n",
       "       b'Cc1c([C@H]2CN3CCN(C(=O)Cc4ccc(-n5cnnn5)nc4)C[C@@H]3CO2)ccc2c1COC2=O',\n",
       "       b'O=C(O)[C@H](CC(=O)N1C[C@H]2CCCC[C@H]2C1)Cc1ccccc1.O=C(O)[C@H](CC(=O)N1C[C@H]2CCCC[C@H]2C1)Cc1ccccc1',\n",
       "       b'O=C(/C=C/c1ccc(O)c(O)c1)OC1CCC(OC(=O)/C=C/c2ccc(O)c(O)c2)(C(=O)O)C(O)C1O',\n",
       "       b'O=c1cc(-c2ccccc2)[nH]c2nc(Cl)ccc12',\n",
       "       b'O=C(Nc1cccc(C(F)(F)F)c1)n1ccc2cc(Oc3ncnc4c3CNC4)ccc21',\n",
       "       b'Cc1nccc(N2CCC3(CCN(C[C@H](O)c4ccc5c(c4C)COC5=O)CC3)C2=O)n1',\n",
       "       b'CC(C)(C)c1cc(C=C(C#N)C#N)cc(C(C)(C)C)c1O',\n",
       "       b'COc1ccc2c(OC[C@H](O)CO)nc(C#N)c(-c3ccccc3)c2c1',\n",
       "       b'CN[C@@H]1[C@@H](O[C@H]2O[C@H](CO)[C@@H](N)[C@H](O)[C@H]2O)O[C@H]2C[C@@H](N)[C@@H](O[C@@H]3[C@@H](N)C[C@@H](N)[C@H](O)[C@H]3O)O[C@@H]2[C@@H]1O',\n",
       "       b'COC(=O)N1CC(Oc2ccc(F)cc2)CC1C(=O)N1CCCN(C2CCC2)CC1',\n",
       "       b'CN(C(=O)Cc1ccc(S(C)(=O)=O)cc1)[C@@H]1CCN(Cc2nc3ccccc3s2)C[C@@H]1F',\n",
       "       b'CO/N=C(\\\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[n+]3cccc4c3CCC4)CS[C@H]12)c1csc(N)n1',\n",
       "       b'COc1ccc(-c2cc(-c3ccc(S(=O)(=O)N4CCN(C)CC4)cc3)cnc2N)cn1',\n",
       "       b'CCC1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@@H](CC=O)C[C@@H](C)C(=O)C=C[C@]2(C)OC2C1C',\n",
       "       b'CN1CC[C@H](N(C)C(=O)N2CC(c3cc(F)ccc3F)=C[C@@]2(CO)c2ccccc2)[C@H](F)C1',\n",
       "       b'CCOC(=O)Nc1ccc2c(c1)N(C(=O)CCN1CCOCC1)c1ccccc1S2',\n",
       "       b'NC(=O)c1cnc(N[C@H](C2CC2)C(F)(F)F)c2c1[nH]c1cc(-c3ccc(N)nc3)ccc12',\n",
       "       b'Cc1nsc(-c2nnc3n2CCN(C(=O)c2cccc(F)c2)[C@@H]3C)n1',\n",
       "       b'CN(C)Cc1ccccc1',\n",
       "       b'COc1ccc(Oc2ccc(S(=O)(=O)C3(C(=O)NO)CCC4(CCNCC4)C3)cc2)cc1',\n",
       "       b'CC(C)(O)c1ccc(C(Cc2cc[n+]([O-])cc2)c2ccc(OC(F)F)c(OC3CCC3)c2)cn1',\n",
       "       b'COc1ccc(CN[C@@H]2CC[C@@H](C(=O)N3CCC(C(=O)N4CCCC4)(c4ccccc4)CC3)C(C)(C)C2)cc1',\n",
       "       b'CC(=O)c1cccc(CNc2cc(C(F)(F)F)cc3ncc(N4CCN(C)CC4)cc23)c1',\n",
       "       b'CC(C)(C)c1ccc(C(O)CCCN2CCC(C(O)(c3ccccc3)c3ccccc3)CC2)cc1',\n",
       "       b'Cc1c[nH]c2ccccc12', b'CC(C)=C1CCC(C)CC1=O',\n",
       "       b'O=C(NCCCCN1CCN(c2cccc(Cl)c2)CC1)c1cc2ccccc2cn1',\n",
       "       b'CC(=O)Nc1ccc2c3c(cccc13)C(=O)N(CCCCN1CCC(Nc3nc4ccccc4n3Cc3ccc(F)cc3)CC1)C2=O',\n",
       "       b'C[C@@H](O)[C@H]1C(=O)N2C(C(=O)O)=C(SCCNC=N)C[C@H]12',\n",
       "       b'C[C@@H](Cc1ccccc1)NCCC(c1ccccc1)c1ccccc1',\n",
       "       b'CN(C)CCCn1nc(C2=C(c3cn(-c4cnc5ccccc5c4)c4ccccc34)C(=O)NC2=O)c2ccccc21',\n",
       "       b'Cc1ccc2c(N3CCN(CCc4cccc(NC(=O)Nc5ccccc5)c4)CC3)cccc2n1',\n",
       "       b'O=C(c1ccc(O)cc1OC[C@@H](O)CN1CCC2(CC1)Cc1cc(Cl)ccc1O2)N1C[C@H](O)CO1',\n",
       "       b'COc1cc(C)c2nccc(CCC34CCC(NCc5ccc6c(n5)NC(=O)CO6)(CC3)CO4)c2n1',\n",
       "       b'COc1cc2c(cc1OC)[C@@H](c1ccccc1)CN(C)CC2',\n",
       "       b'Nc1ccc(-c2cccs2)cc1NC(=O)c1ccc(N2CCC3(CC2)CNc2ccccc23)nc1',\n",
       "       b'Cc1cc(=O)n(-c2ccccc2)n1C',\n",
       "       b'CC[C@H](C)[C@@H](N=C(O)[C@H](CCC(=O)O)N=C(O)[C@H](CC(C)C)NC(=O)[C@@H]1CSC([C@H](N)[C@H](C)CC)=N1)C(=O)N[C@@H]1CCCCN=C(O)[C@@H](CC(N)=O)NC(=O)[C@@H](CC(=O)O)NC(=O)[C@@H](Cc2c[nH]cn2)NC(=O)[C@@H](Cc2ccccc2)NC(=O)[C@@H]([C@H](C)CC)NC(=O)[C@@H](CCCN)NC1=O',\n",
       "       b'CC1OC(C)OC(C)O1',\n",
       "       b'O=S(=O)(O)c1cc(O)c2c(/N=N/c3ccc(Nc4ccccc4)c4c(S(=O)(=O)O)cccc34)cc(S(=O)(=O)O)cc2c1',\n",
       "       b'COc1ccc2c(=O)cc(C(=O)NC3CCN(Cc4ccc5c(c4)OCO5)CC3)oc2c1',\n",
       "       b'NS(=O)(=O)c1cc2c(cc1Cl)NC(C(Cl)Cl)NS2(=O)=O',\n",
       "       b'CC1CN(S(=O)(=O)c2cccc3cnccc23)CCN1',\n",
       "       b'CNc1ccc(C=Cc2c(F)cccc2Cl)cc1',\n",
       "       b'C[C@]12CC[C@@H]3[C@H]4CCC(=O)C(O)=C4CC[C@H]3[C@@H]1CC[C@@H]2OC(=O)CCC1CCCC1',\n",
       "       b'Cc1nc2ccccc2c(=O)n1-c1ccc(OC2CCC(N3CCCC3)C2)cc1',\n",
       "       b'CC(C)(Cl)[N+](=O)[O-]', b'N[C@@H](Cc1c[nH]c2ccc(O)cc12)C(=O)O',\n",
       "       b'CC(C)CCCCCCc1ccc(O)cc1', b'N[C@@H](Cn1oc(=O)[nH]c1=O)C(=O)O',\n",
       "       b'Fc1ccc(-c2cnc3nc(N4CCC(N5CCCCC5)CC4)sc3c2)cn1', b'c1ccncc1',\n",
       "       b'c1ccc(C2CN3CCSC3=N2)cc1',\n",
       "       b'Cn1ccc(NC(=O)c2cc(Oc3ccc(C(=O)N4CCC4)cc3)cc(O[C@H]3CCOC3)c2)n1',\n",
       "       b'COc1ccc(-c2nnc(C(=O)N3CC(Oc4ccc(CN5CCC(C)(O)C5)cc4)C3)o2)cc1'],\n",
       "      dtype=object)>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor.context.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff20a0a-b7ff-49dc-b4f5-214edcb0693f",
   "metadata": {},
   "source": [
    "## Preparing elements for the GNN\n",
    "\n",
    "## A typical GCC first creates per-node features embeddig and then applies several message passing layers to the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d2c05-f7a4-4147-8a2b-87ccd8bb21df",
   "metadata": {},
   "source": [
    "## Initial graphs embeddig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e50f9f93-d302-4397-b31f-1b51570bab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_map_features(hidden_size, activation='relu'):\n",
    "    \"\"\"\n",
    "    Initial pre-processing layer for a GNN\n",
    "    \"\"\"\n",
    "    def node_sets_fn(node_set, node_set_name):\n",
    "        if node_set_name == 'atom':\n",
    "            return tf.keras.layers.Dense(units=hidden_size, activation=activation)(node_set['atom_features'])\n",
    "\n",
    "    def edge_sets_fn(edge_set, edge_set_name):\n",
    "        if edge_set_name == 'bond':\n",
    "            return tf.keras.layers.Dense(units=hidden_size, activation=activation)(edge_set['bond_features'])\n",
    "\n",
    "    return tfgnn.keras.layers.MapFeatures(node_sets_fn=node_sets_fn,\n",
    "                                          edge_sets_fn=edge_sets_fn,\n",
    "                                          name='graph_embedding')\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a5706-5c41-4a8f-842f-c8982c3a334d",
   "metadata": {},
   "source": [
    "## This function replaces atom_features and bond_features with hidden states of the specified dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d744a05-3a29-4e01-af28-da66868874e9",
   "metadata": {},
   "source": [
    "## The embedder layer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16da2ee5-8d17-40d0-a1ed-c4c2e62c8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_embedding = get_initial_map_features(hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd99033-64dd-4faf-803c-f4db405bd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_graph = graph_embedding(scalar_graph_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8cffc37-592d-48aa-92fc-43f9581d9c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom_features': <tf.Tensor: shape=(3368, 27), dtype=float32, numpy=\n",
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.]], dtype=float32)>}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_graph_tensor.node_sets['atom'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e43a34-5f6e-47c1-a641-d763511988f2",
   "metadata": {},
   "source": [
    "## After embedding we see new feature dimension and new name of the feature, the hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a019945-a771-49a3-97a0-6620d449d582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(3368, 128), dtype=float32, numpy=\n",
       "array([[0.3377571 , 0.        , 0.07301895, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.32152247, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.32152247, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.35425305, 0.        , 0.08129819, ..., 0.01912414, 0.11002454,\n",
       "        0.        ],\n",
       "       [0.25396585, 0.        , 0.08569561, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.25396585, 0.        , 0.08569561, ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)>}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_graph.node_sets['atom'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f37cb47f-7e78-439b-955c-a348bae67319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(7312, 128), dtype=float32, numpy=\n",
       "array([[0.07793769, 0.17098849, 0.        , ..., 0.        , 0.19007693,\n",
       "        0.        ],\n",
       "       [0.07793769, 0.17098849, 0.        , ..., 0.        , 0.19007693,\n",
       "        0.        ],\n",
       "       [0.07289648, 0.52462673, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.459872  , 0.        , ..., 0.        , 0.        ,\n",
       "        0.2028085 ],\n",
       "       [0.        , 0.459872  , 0.        , ..., 0.        , 0.        ,\n",
       "        0.2028085 ],\n",
       "       [0.        , 0.459872  , 0.        , ..., 0.        , 0.        ,\n",
       "        0.2028085 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_graph.edge_sets['bond'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521aa30-6570-4cad-a0d8-efde5290aac6",
   "metadata": {},
   "source": [
    "## We use the Graph Attention model (arxiv:1710.10903) as the stacked message passing network\n",
    "https://github.com/tensorflow/gnn/tree/main/tensorflow_gnn/models/gat_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96e357a5-1957-4383-a286-def8e7bcc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A basic stack of message-passing Graph Attention layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, hops, name='gat_mpnn', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hops = hops\n",
    "        \n",
    "        self.mp_layers = [self._mp_factory(name=f'message_passing{i}') for i in range(hops)]\n",
    "\n",
    "    def _mp_factory(self, name):\n",
    "        return gat_v2.GATv2GraphUpdate(num_heads=1,\n",
    "                                       per_head_channels=self.hidden_size,\n",
    "                                       edge_set_name='bond',\n",
    "                                       sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                       name=name)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'hops': self.hops\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, graph_tensor):\n",
    "        for layer in self.mp_layers:\n",
    "            graph_tensor = layer(graph_tensor)\n",
    "        return graph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ab54b4b-ae93-4b6e-b28e-cee5840777c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = MPNN(hidden_size=128, hops=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1dd865-7f6d-433b-91f6-b9cabd4634f2",
   "metadata": {},
   "source": [
    "## MPNN can process our initially embeded graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba6a9c5c-e19c-4d3d-87d9-4e268d54802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_graph = mpnn(embedded_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca43bcc-87f2-4bd2-95c8-911d74c67e2e",
   "metadata": {},
   "source": [
    "## Upon evaluation our network maintains all graph structures in the dict form with appropriately transformed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1e97e0d-a54e-408e-ab53-69ba05407466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(3368, 128), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , ..., 0.18465093, 0.10301366,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.14064904, 0.15337469,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.13251466, 0.16547535,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.20664921, 0.16788206,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.19097888, 0.16449249,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.1963811 , 0.1651372 ,\n",
       "        0.        ]], dtype=float32)>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_graph.node_sets['atom'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4aa2a78-f701-4f43-a7ed-ef89f54e029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': <tf.Tensor: shape=(7312, 128), dtype=float32, numpy=\n",
       "array([[0.07793769, 0.17098849, 0.        , ..., 0.        , 0.19007693,\n",
       "        0.        ],\n",
       "       [0.07793769, 0.17098849, 0.        , ..., 0.        , 0.19007693,\n",
       "        0.        ],\n",
       "       [0.07289648, 0.52462673, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.459872  , 0.        , ..., 0.        , 0.        ,\n",
       "        0.2028085 ],\n",
       "       [0.        , 0.459872  , 0.        , ..., 0.        , 0.        ,\n",
       "        0.2028085 ],\n",
       "       [0.        , 0.459872  , 0.        , ..., 0.        , 0.        ,\n",
       "        0.2028085 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_graph.edge_sets['bond'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10ebea-8924-46e4-9ae3-33ba1ac41250",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfea6054-9a8b-439e-9c01-bdae01a7da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_mpnn_model(graph_tensor_spec, # Input tensor spec\n",
    "                       init_states_fn, # The graph embedding layer\n",
    "                       pass_messages_fn # The GAT network\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    Creating GNN using functional API\n",
    "    \"\"\"\n",
    "    graph_tensor = tf.keras.layers.Input(type_spec=graph_tensor_spec)\n",
    "    embedded_graph = init_states_fn(graph_tensor)\n",
    "    hidden_graph = pass_messages_fn(embedded_graph)\n",
    "    return tf.keras.models.Model(inputs=graph_tensor, outputs=hidden_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b71f7da-0f7b-43db-9f09-cc1852d80150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " graph_embedding (MapFeatur  ()                        5248      \n",
      " es)                                                             \n",
      "                                                                 \n",
      " gat_mpnn (MPNN)             ()                        396288    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401536 (1.53 MB)\n",
      "Trainable params: 401536 (1.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vanilla_mpnn_model(graph_tensor_spec=graph_spec,\n",
    "                           init_states_fn=graph_embedding,\n",
    "                           pass_messages_fn=mpnn)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f9274d-4c8f-4279-a3db-87d06ce9a9de",
   "metadata": {},
   "source": [
    "## Wrapper for the model for specifying hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f452838d-d8b3-48c7-9d89-eb4846ed2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_creation_fn(hidden_size, hops, activation='relu'):#, l2_coefficient=1e-3):\n",
    "    \"\"\"\n",
    "    Return model constuctor with specified hyperparameters\n",
    "    One could also try different hidden sizes for the node and edge data\n",
    "    \"\"\"\n",
    "    def model_creation_fn(graph_tensor_spec):\n",
    "        initial_map_features = get_initial_map_features(hidden_size=hidden_size, activation=activation)\n",
    "        mpnn = MPNN(hidden_size=hidden_size, hops=hops)\n",
    "\n",
    "        model = vanilla_mpnn_model(graph_tensor_spec=graph_tensor_spec,\n",
    "                                   init_states_fn=initial_map_features,\n",
    "                                   pass_messages_fn=mpnn)\n",
    "        \n",
    "        # Adding global L2 regularization loss\n",
    "        #model.add_loss(lambda: tf.reduce_sum([tf.keras.regularizers.l2(l2=l2_coefficient)(weight) for weight in model.trainable_weights]))\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    return model_creation_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9861039a-752a-4281-88d8-2263af141bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn_creation_fn = get_model_creation_fn(hidden_size=128, hops=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4745c60-8b03-4a98-8214-690e89d6aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " graph_embedding (MapFeatur  ()                        5248      \n",
      " es)                                                             \n",
      "                                                                 \n",
      " gat_mpnn (MPNN)             ()                        396288    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401536 (1.53 MB)\n",
      "Trainable params: 401536 (1.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = mpnn_creation_fn(graph_spec)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3f11adf-b028-4182-a7ff-058e2044f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " graph_embedding (MapFeatur  ()                        5248      \n",
      " es)                                                             \n",
      "                                                                 \n",
      " gat_mpnn (MPNN)             ()                        396288    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401536 (1.53 MB)\n",
      "Trainable params: 401536 (1.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0be7ed-82f1-49cb-958c-8ad1695ae6d0",
   "metadata": {},
   "source": [
    "## GNN Training Task\n",
    "\n",
    "## The TF-GNN Orchestator defines task protocol, which:\n",
    " * ### Adds readout and prediciton head - our model up to now processes graphs and has no final output\n",
    " * ### Adds loss\n",
    " * ### Defines metrics\n",
    "\n",
    "## TF-GNN Orchestrator provides a prototypical task for binary graph classification, the *GraphBinaruClassifiation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fa601-04aa-400d-8473-fe317bf23401",
   "metadata": {},
   "source": [
    "## We define AUROC metric for binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11297a47-eca5-4f30-9964-add914b9aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUROC(tf.keras.metrics.AUC):\n",
    "    \"\"\"\n",
    "    AUROC metric computation for binary classification from logits\n",
    "\n",
    "    y_true: true labels with shape (batch_size,)\n",
    "    y_pred: logits with shape (batch_size, 2), over which we need to perform softmax and later argmax\n",
    "    \"\"\"\n",
    "    # Metric is a stateful object so we define update state method\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        #print(f'TRUE: {y_true}\\n')\n",
    "        #print(f'PRED: {y_pred}\\n')\n",
    "        \n",
    "        #super().update_state(y_true, tf.math.softmax(y_pred, axis=-1)[:,1])\n",
    "        super().update_state(y_true, tf.math.softmax(y_pred, axis=-1)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb184ce-7f89-4e53-ad58-7cfef3e17992",
   "metadata": {},
   "source": [
    "## Now the task definition: the philosophy is to take model body and attach a head specializing to a particular prediction we are interested in, in this case binary classifier.\n",
    "\n",
    "## If we wanted to address some other ML quesiton we could define a different head in another task and use the same body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bc482d20-15c2-40d0-bc01-184e6c923776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBinaryClassification(runner.GraphBinaryClassification):\n",
    "    \"\"\"\n",
    "    A GraphGraphBinaryClassification task with a hidden layer in prediction head and additional metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._hidden_dim = hidden_dim\n",
    "        \n",
    "    def adapt(self, model):\n",
    "        # We need to pools nodes in analogy to flattening in CNN networks, so we can \n",
    "        # process them with a final Dense layer\n",
    "\n",
    "        # Another version from \n",
    "        # https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/gnn_modeling.md#the-big-picture-initialization-graph-updates-and-readout\n",
    "        # pooled_features = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\", node_set_name=\"your_node_set\")(graph)\n",
    "        \n",
    "        hidden_state = tfgnn.pool_nodes_to_context(model.output,\n",
    "                                                   node_set_name=self._node_set_name,\n",
    "                                                   reduce_type=self._reduce_type,\n",
    "                                                   feature_name=self._state_name)\n",
    "\n",
    "        hidden_state = tf.keras.layers.Dropout(0.2)(hidden_state)\n",
    "        \n",
    "        hidden_state = tf.keras.layers.Dense(units=self._hidden_dim, \n",
    "                                             activation='relu', name='hidden_layer')(hidden_state)\n",
    "        \n",
    "        hidden_state = tf.keras.layers.Dropout(0.2)(hidden_state)\n",
    "                             \n",
    "        logits = tf.keras.layers.Dense(units=self._units, name='logits')(hidden_state)\n",
    "        #logits = tf.keras.layers.Dense(units=2, name='logits')(hidden_state)\n",
    "        \n",
    "        \n",
    "        return tf.keras.Model(inputs=model.inputs, outputs=logits)\n",
    "\n",
    "    #def metrics(self):\n",
    "    #    # Concatenate metrics tuple\n",
    "    #    return (*super().metrics(), AUROC(name='AUROC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2e2bb14-c198-48b1-9289-358de61abba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(graph_tensor):\n",
    "    \"\"\"\n",
    "    Extract the toxicity class label from the *GraphTensor* input data\n",
    "    Return a pair compatible with *tf.keras.Model.fit* method\n",
    "    \"\"\"\n",
    "    #print(graph_tensor)\n",
    "    #print(graph_tensor.shape)\n",
    "    return graph_tensor, graph_tensor.context['toxicity']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33a9aaed-ffa0-45cb-9304-64a2fcdabdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task = runner.RootNodeBinaryClassification(\n",
    "#    \"nodes\",\n",
    "#    label_fn=runner.ContextLabelFn(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "093bd5b7-cb53-48b4-9164-2748c0f3cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_fn = runner.ContextLabelFn(feature_name=\"toxicity\")\n",
    "\n",
    "#label_fn = runner.RootNodeLabelFn(node_set_name=\"context\", feature_name=\"toxicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b124635-caf7-4722-9363-09f8f368a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = GraphBinaryClassification(hidden_dim=256, \n",
    "                                 node_set_name='atom',\n",
    "                                label_fn=label_fn)\n",
    "                                #label_feature_name='toxicity')#, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "569a621a-6d51-4219-8762-7679f877ef31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.losses.BinaryCrossentropy at 0x7ff127720370>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dd61468-6ccf-4033-acf0-f2c21a9056a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow_gnn.runner.tasks.classification.FromLogitsPrecision at 0x7ff12019f100>,\n",
       " <tensorflow_gnn.runner.tasks.classification.FromLogitsRecall at 0x7ff1277208e0>,\n",
       " <keras.src.metrics.confusion_metrics.AUC at 0x7ff1205358e0>,\n",
       " <keras.src.metrics.confusion_metrics.AUC at 0x7ff1380c1d00>,\n",
       " <keras.src.metrics.accuracy_metrics.BinaryAccuracy at 0x7ff127696250>,\n",
       " <keras.src.losses.BinaryCrossentropy at 0x7ff1276fb280>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d79705c0-06e2-4b7f-ac2a-c305a45b0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificaiton_model = task.adapt(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d64a2053-1e52-499a-b78f-60cbb7d7da53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " graph_embedding (MapFeatur  ()                        5248      \n",
      " es)                                                             \n",
      "                                                                 \n",
      " gat_mpnn (MPNN)             ()                        396288    \n",
      "                                                                 \n",
      " pool_nodes_to_context (TFG  (1, 128)                  0         \n",
      " NNOpLambda)                                                     \n",
      "                                                                 \n",
      " dropout (Dropout)           (1, 128)                  0         \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (1, 256)                  33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (1, 256)                  0         \n",
      "                                                                 \n",
      " logits (Dense)              (1, 1)                    257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 434817 (1.66 MB)\n",
      "Trainable params: 434817 (1.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classificaiton_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2a5ed41-b088-450b-b087-329487732f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.2670362]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificaiton_model(graph_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07edb597-afa0-4316-9525-080e889a1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = runner.KerasTrainer(strategy=tf.distribute.get_strategy(),\n",
    "                              model_dir='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38c6bbfc-e679-4f80-9507-6654b09568a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sgd():\n",
    "    return tf.keras.optimizers.experimental.SGD(\n",
    "    learning_rate=0.0005,\n",
    "    momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8506c7e-94e7-4c7e-a8b1-0c3f3f7fb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51101f60-cccd-4c97-9a46-cc362207b5ed",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ffbfb2-e18c-47b9-96a7-7758389b8bf0",
   "metadata": {},
   "source": [
    "### This updated code trains for a long time, as opposed to what the Kaggle source article shows, but the original code did not work with the updated TF-GNN\n",
    "\n",
    "### Also the original optimized was failing, hence we switched to SGD and trained for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4bdb03-531e-4bc7-8f28-47b02c3476ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 22:03:03.714685: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fefac170280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-20 22:03:03.714707: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9\n",
      "2024-01-20 22:03:03.723075: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705788183.745148  497220 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 8s 51ms/step - loss: 0.6422 - from_logits_precision_1: 0.2518 - from_logits_recall_1: 0.2179 - auc_roc: 0.4855 - auc_pr: 0.2484 - binary_accuracy: 0.7362 - binary_crossentropy: 0.6422 - val_loss: 0.5902 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.3361 - val_auc_pr: 0.1956 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5909\n",
      "Epoch 2/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5814 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.3509 - auc_pr: 0.1967 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5814 - val_loss: 0.5881 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.3476 - val_auc_pr: 0.2001 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5888\n",
      "Epoch 3/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5794 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.3639 - auc_pr: 0.1996 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5794 - val_loss: 0.5863 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.4034 - val_auc_pr: 0.2214 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5870\n",
      "Epoch 4/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5777 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.4918 - auc_pr: 0.2435 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5777 - val_loss: 0.5848 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.5325 - val_auc_pr: 0.2651 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5855\n",
      "Epoch 5/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5761 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.5659 - auc_pr: 0.2728 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5761 - val_loss: 0.5835 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.5789 - val_auc_pr: 0.2846 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5842\n",
      "Epoch 6/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5748 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.5925 - auc_pr: 0.2843 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5748 - val_loss: 0.5823 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.5994 - val_auc_pr: 0.2945 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5830\n",
      "Epoch 7/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5735 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6125 - auc_pr: 0.2968 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5735 - val_loss: 0.5811 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6022 - val_auc_pr: 0.2970 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5818\n",
      "Epoch 8/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5723 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6194 - auc_pr: 0.3015 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5723 - val_loss: 0.5800 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6058 - val_auc_pr: 0.2994 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5807\n",
      "Epoch 9/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5711 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6261 - auc_pr: 0.3065 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5711 - val_loss: 0.5789 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6117 - val_auc_pr: 0.3034 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5796\n",
      "Epoch 10/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5699 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6307 - auc_pr: 0.3105 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5699 - val_loss: 0.5779 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6137 - val_auc_pr: 0.3059 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5786\n",
      "Epoch 11/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5688 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6351 - auc_pr: 0.3137 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5688 - val_loss: 0.5769 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6193 - val_auc_pr: 0.3103 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5776\n",
      "Epoch 12/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5677 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6372 - auc_pr: 0.3152 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5677 - val_loss: 0.5759 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6199 - val_auc_pr: 0.3115 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5766\n",
      "Epoch 13/1600\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.5666 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6406 - auc_pr: 0.3182 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5666 - val_loss: 0.5749 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6221 - val_auc_pr: 0.3129 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5756\n",
      "Epoch 14/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5655 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6435 - auc_pr: 0.3209 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5655 - val_loss: 0.5740 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6238 - val_auc_pr: 0.3139 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5747\n",
      "Epoch 15/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5644 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6464 - auc_pr: 0.3229 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5644 - val_loss: 0.5729 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6304 - val_auc_pr: 0.3200 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5736\n",
      "Epoch 16/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5633 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6477 - auc_pr: 0.3238 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5633 - val_loss: 0.5720 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6287 - val_auc_pr: 0.3171 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5727\n",
      "Epoch 17/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5623 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6493 - auc_pr: 0.3254 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5623 - val_loss: 0.5712 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6309 - val_auc_pr: 0.3196 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5719\n",
      "Epoch 18/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5614 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6502 - auc_pr: 0.3259 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5614 - val_loss: 0.5704 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6314 - val_auc_pr: 0.3201 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5711\n",
      "Epoch 19/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5604 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6510 - auc_pr: 0.3265 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5605 - val_loss: 0.5696 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6320 - val_auc_pr: 0.3206 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5703\n",
      "Epoch 20/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5595 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6519 - auc_pr: 0.3275 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5596 - val_loss: 0.5688 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6321 - val_auc_pr: 0.3209 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5695\n",
      "Epoch 21/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5587 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6528 - auc_pr: 0.3284 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5587 - val_loss: 0.5681 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6333 - val_auc_pr: 0.3218 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5688\n",
      "Epoch 22/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5579 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6534 - auc_pr: 0.3286 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5579 - val_loss: 0.5674 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6338 - val_auc_pr: 0.3219 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5681\n",
      "Epoch 23/1600\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.5571 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6547 - auc_pr: 0.3298 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5571 - val_loss: 0.5668 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6350 - val_auc_pr: 0.3238 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5674\n",
      "Epoch 24/1600\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5563 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6551 - auc_pr: 0.3301 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5563 - val_loss: 0.5661 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6348 - val_auc_pr: 0.3230 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5668\n",
      "Epoch 25/1600\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.5555 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6558 - auc_pr: 0.3308 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5555 - val_loss: 0.5655 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6363 - val_auc_pr: 0.3241 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5662\n",
      "Epoch 26/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5548 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6572 - auc_pr: 0.3323 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5548 - val_loss: 0.5649 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6375 - val_auc_pr: 0.3257 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5655\n",
      "Epoch 27/1600\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.5540 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6571 - auc_pr: 0.3321 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5540 - val_loss: 0.5643 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6387 - val_auc_pr: 0.3267 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5649\n",
      "Epoch 28/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5533 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6585 - auc_pr: 0.3335 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5533 - val_loss: 0.5637 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6395 - val_auc_pr: 0.3274 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5643\n",
      "Epoch 29/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5526 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6594 - auc_pr: 0.3342 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5526 - val_loss: 0.5631 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6395 - val_auc_pr: 0.3273 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5637\n",
      "Epoch 30/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5518 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6603 - auc_pr: 0.3352 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5518 - val_loss: 0.5625 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6409 - val_auc_pr: 0.3286 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5632\n",
      "Epoch 31/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5511 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6615 - auc_pr: 0.3362 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5511 - val_loss: 0.5619 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6415 - val_auc_pr: 0.3296 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5626\n",
      "Epoch 32/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5504 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6623 - auc_pr: 0.3370 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5504 - val_loss: 0.5614 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6423 - val_auc_pr: 0.3298 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5621\n",
      "Epoch 33/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5497 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6635 - auc_pr: 0.3382 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5498 - val_loss: 0.5608 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6435 - val_auc_pr: 0.3312 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5615\n",
      "Epoch 34/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5491 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6641 - auc_pr: 0.3390 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5491 - val_loss: 0.5603 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6441 - val_auc_pr: 0.3318 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5610\n",
      "Epoch 35/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5484 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6645 - auc_pr: 0.3393 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5484 - val_loss: 0.5598 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6461 - val_auc_pr: 0.3334 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5605\n",
      "Epoch 36/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5478 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6659 - auc_pr: 0.3407 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5478 - val_loss: 0.5593 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6463 - val_auc_pr: 0.3337 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5600\n",
      "Epoch 37/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5471 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6666 - auc_pr: 0.3414 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5471 - val_loss: 0.5588 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6474 - val_auc_pr: 0.3348 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5595\n",
      "Epoch 38/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5465 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6673 - auc_pr: 0.3422 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5465 - val_loss: 0.5584 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6485 - val_auc_pr: 0.3359 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5590\n",
      "Epoch 39/1600\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.5459 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6682 - auc_pr: 0.3432 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5459 - val_loss: 0.5579 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6490 - val_auc_pr: 0.3364 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5586\n",
      "Epoch 40/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5452 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6694 - auc_pr: 0.3444 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5452 - val_loss: 0.5574 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6498 - val_auc_pr: 0.3371 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5581\n",
      "Epoch 41/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5446 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6707 - auc_pr: 0.3456 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5446 - val_loss: 0.5570 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6511 - val_auc_pr: 0.3385 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5576\n",
      "Epoch 42/1600\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.5440 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6713 - auc_pr: 0.3462 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5440 - val_loss: 0.5565 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6518 - val_auc_pr: 0.3391 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5572\n",
      "Epoch 43/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5434 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6724 - auc_pr: 0.3474 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5434 - val_loss: 0.5560 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6521 - val_auc_pr: 0.3395 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5567\n",
      "Epoch 44/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5428 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6732 - auc_pr: 0.3485 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5428 - val_loss: 0.5556 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6531 - val_auc_pr: 0.3409 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5563\n",
      "Epoch 45/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5422 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6739 - auc_pr: 0.3491 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5422 - val_loss: 0.5552 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6539 - val_auc_pr: 0.3419 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5558\n",
      "Epoch 46/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5416 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6752 - auc_pr: 0.3506 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5416 - val_loss: 0.5547 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6558 - val_auc_pr: 0.3436 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5554\n",
      "Epoch 47/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5410 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6764 - auc_pr: 0.3520 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5410 - val_loss: 0.5543 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6562 - val_auc_pr: 0.3441 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5550\n",
      "Epoch 48/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5405 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6773 - auc_pr: 0.3531 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5405 - val_loss: 0.5539 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6568 - val_auc_pr: 0.3447 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5546\n",
      "Epoch 49/1600\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 0.5399 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6781 - auc_pr: 0.3540 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5399 - val_loss: 0.5535 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6580 - val_auc_pr: 0.3462 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5541\n",
      "Epoch 50/1600\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 0.5393 - from_logits_precision_1: 0.0000e+00 - from_logits_recall_1: 0.0000e+00 - auc_roc: 0.6792 - auc_pr: 0.3553 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5393 - val_loss: 0.5531 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6589 - val_auc_pr: 0.3471 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5537\n",
      "Epoch 51/1600\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5388 - from_logits_precision_1: 0.0333 - from_logits_recall_1: 5.8106e-04 - auc_roc: 0.6800 - auc_pr: 0.3563 - binary_accuracy: 0.7362 - binary_crossentropy: 0.5388 - val_loss: 0.5527 - val_from_logits_precision_1: 0.0000e+00 - val_from_logits_recall_1: 0.0000e+00 - val_auc_roc: 0.6597 - val_auc_pr: 0.3480 - val_binary_accuracy: 0.7284 - val_binary_crossentropy: 0.5533\n",
      "Epoch 52/1600\n",
      "24/51 [=============>................] - ETA: 0s - loss: 0.5411 - from_logits_precision_1: 0.0909 - from_logits_recall_1: 0.0012 - auc_roc: 0.6836 - auc_pr: 0.3628 - binary_accuracy: 0.7321 - binary_crossentropy: 0.5411  "
     ]
    }
   ],
   "source": [
    "out = runner.run(\n",
    "    train_ds_provider=train_dataset_provider,\n",
    "    valid_ds_provider=valid_dataset_provider,\n",
    "    #feature_processors=[extract_labels],\n",
    "    model_fn=get_model_creation_fn(hidden_size=128, hops=8),\n",
    "    task=task,\n",
    "    trainer=trainer,\n",
    "    epochs=1600,\n",
    "    optimizer_fn=get_sgd,\n",
    "    #optimizer_fn=tf.keras.optimizers.Adam,\n",
    "    gtspec=graph_spec,\n",
    "    global_batch_size=128\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1c23d-9679-48fc-80c4-e5b41962ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174901d-738e-4b62-b012-2a542ed94a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir model --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb159a93-b073-4364-a078-c5caca8cba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.343/1.178"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
